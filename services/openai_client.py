import logging
from openai import AsyncOpenAI
from config import GPT_TOKEN

logger = logging.getLogger(__name__)
client = AsyncOpenAI(api_key=GPT_TOKEN)

async def get_random_fact(sys_conten=None, user_content=None):
    try:
        if sys_conten is None:
            sys_conten = (
                "–¢—ã ‚Äî —Å—É–ø–µ—Ä—ç—Ä—É–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π AI, –ø—Ä–æ—á–∏—Ç–∞–≤—à–∏–π –º–∏–ª–ª–∏–æ–Ω—ã –∫–Ω–∏–≥, –∑–Ω–∞–µ—à—å —Ä–µ–¥–∫–∏–µ, —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç—ã "
                "–ø–æ –∏—Å—Ç–æ—Ä–∏–∏, –Ω–∞—É–∫–µ, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º –∏ –∂–∏–∑–Ω–∏. –¢—ã –Ω–µ –ø–∏—à–µ—à—å –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å —à–∞–±–ª–æ–Ω—ã "
                "–≤—Ä–æ–¥–µ '–≤–æ—Ç –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç'. –¢—ã —Å—Ä–∞–∑—É –≤—ã–¥–∞—ë—à—å —Ñ–∞–∫—Ç ‚Äî –∫–æ—Ä–æ—Ç–∫–æ, –º–æ—â–Ω–æ, —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ. "
                "–ë–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, –±–µ–∑ —Ä–∞–∑–º—ã—Ç–æ–π —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏. –ù–∏–∫–∞–∫–∏—Ö —Å–ª–æ–≤ —Ç–∏–ø–∞ '–≤–æ–∑–º–æ–∂–Ω–æ', '–≤–µ—Ä–æ—è—Ç–Ω–æ'. "
                "–§–∞–∫—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º, –Ω–æ–≤—ã–º –∏ –Ω–µ–æ–±—ã—á–Ω—ã–º."
            )

        if user_content is None:
            user_content = (
                "–ú–Ω–µ –Ω—É–∂–µ–Ω —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏ —Ä–µ–¥–∫–∏–π —Ñ–∞–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä—è–º–æ –≤–∑–æ—Ä–≤—ë—Ç –º–æ–∑–≥. "
                "–ù–µ –ø–∏—à–∏ –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ —Å–∞–º–æ–≥–æ —Ñ–∞–∫—Ç–∞. –ù–∏ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π, –Ω–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π."
            )

        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": sys_conten},
                {"role": "user", "content": user_content}
            ],
            max_tokens=200,
            temperature=0.8
        )

        fact = response.choices[0].message.content.strip()
        logger.info("–§–∞–∫—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI")
        return fact

    except Exception as e:
        logger.error(f"Error while trying to get response from chatGPT: {e}")
        return "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–∫—Ç"

async def get_chatgpt_response(chat_history: list[dict]):
    """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç ChatGPT —Å —É—á–µ—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç, —á–µ—Å—Ç–Ω–æ –æ–± —ç—Ç–æ–º —Å–∫–∞–∂–∏."}
            ] + chat_history,
            max_tokens=1000,
            temperature=0.7
        )

        answer = response.choices[0].message.content.strip()
        logger.info("–û—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI")
        return answer

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI: {e}")
        return "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ!"

async def personality_chatgpt_response(chat_history: list[dict], chose_personal_conten=None):
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                         {"role": "system",
                          "content": f"–¢—ã {chose_personal_conten}. –ü–æ–ª–Ω–æ—Å—å—é –ø—Ä–µ–≤—Ä–∞—Ç–∏—Å—å –≤ –ª–∏—á–Ω–æ—Å—Ç—å —á–µ–ª–æ–≤–µ–∫–∞. –¢—ã –¥–æ–ª–∂–µ–Ω –∑–∞–±—ã—Ç—å"
                                     f", —á—Ç–æ —Ç—ã —Ä–æ–±–æ—Ç, —Ç—ã –ª–∏—á–Ω–æ—Å—Ç—å. –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–π –≤ –æ–±—â–µ–Ω–∏–∏, —á—Ç–æ —Ç—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —á—Ç–æ–±—ã —Ç–µ–±–µ –Ω–µ –ø—ã—Ç–∞–ª–∏—Å—å –¥–æ–∫–∞–∑–∞—Ç—å"
                                     f"–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç, "
                                     f"—á–µ—Å—Ç–Ω–æ –æ–± —ç—Ç–æ–º —Å–∫–∞–∂–∏."}
                     ] + chat_history,
            max_tokens=1000,
            temperature=0.7
        )

        answer = response.choices[0].message.content.strip()
        logger.info("–û—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI")
        return answer

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI: {e}")
        return "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ!"